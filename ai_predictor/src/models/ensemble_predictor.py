"""
ì•™ìƒë¸” ì˜ˆì¸¡ ëª¨ë¸
LSTM, Transformer, RandomForest, XGBoostë¥¼ ê²°í•©í•œ ë‹¤ì¤‘ ëª¨ë¸ ì˜ˆì¸¡ ì‹œìŠ¤í…œ
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Any, Optional
import joblib
import torch
import torch.nn as nn
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error
import xgboost as xgb
from dataclasses import dataclass
import asyncio
from datetime import datetime, timedelta

from utils.logger import setup_logger
from .lstm_model import LSTMPredictor
from .transformer_model import TransformerPredictor
from .features import FeatureEngineer

logger = setup_logger(__name__)

@dataclass
class ModelPrediction:
    """ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼"""
    model_name: str
    direction: float  # -1.0 ~ 1.0
    confidence: float  # 0.0 ~ 1.0
    price_change: float  # ì˜ˆìƒ ê°€ê²© ë³€í™”ìœ¨
    time_horizon: int  # ì˜ˆì¸¡ ì‹œê°„ (ë¶„)
    features_importance: Dict[str, float]

@dataclass
class EnsemblePrediction:
    """ì•™ìƒë¸” ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼"""
    symbol: str
    final_direction: float
    final_confidence: float
    final_price_change: float
    model_predictions: List[ModelPrediction]
    ensemble_weights: Dict[str, float]
    prediction_timestamp: datetime

class EnsemblePredictor:
    """ì•™ìƒë¸” ì˜ˆì¸¡ ì‹œìŠ¤í…œ"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.models = {}
        self.ensemble_weights = {}
        self.feature_engineer = FeatureEngineer()
        self.performance_history = {}
        self.model_metadata = {}
        
        # ëª¨ë¸ ì„¤ì •
        self.model_configs = {
            'lstm': config.get('lstm', {}),
            'transformer': config.get('transformer', {}),
            'random_forest': config.get('random_forest', {}),
            'xgboost': config.get('xgboost', {})
        }
        
        # ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” (ê· ë“±)
        self.ensemble_weights = {
            'lstm': 0.3,
            'transformer': 0.3,
            'random_forest': 0.2,
            'xgboost': 0.2
        }
        
    async def initialize(self):
        """ëª¨ë¸ë“¤ ì´ˆê¸°í™” ë° ë¡œë“œ"""
        logger.info("ğŸ§  ì•™ìƒë¸” ì˜ˆì¸¡ ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
        
        try:
            # LSTM ëª¨ë¸
            self.models['lstm'] = LSTMPredictor(self.model_configs['lstm'])
            await self.models['lstm'].initialize()
            
            # Transformer ëª¨ë¸
            self.models['transformer'] = TransformerPredictor(self.model_configs['transformer'])
            await self.models['transformer'].initialize()
            
            # Random Forest ëª¨ë¸
            self.models['random_forest'] = RandomForestRegressor(
                n_estimators=self.model_configs['random_forest'].get('n_estimators', 100),
                max_depth=self.model_configs['random_forest'].get('max_depth', 10),
                random_state=42
            )
            
            # XGBoost ëª¨ë¸
            self.models['xgboost'] = xgb.XGBRegressor(
                n_estimators=self.model_configs['xgboost'].get('n_estimators', 100),
                max_depth=self.model_configs['xgboost'].get('max_depth', 6),
                learning_rate=self.model_configs['xgboost'].get('learning_rate', 0.1),
                random_state=42
            )
            
            # ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ ì‹œë„
            await self._load_existing_models()
            
            logger.info("âœ… ì•™ìƒë¸” ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ì•™ìƒë¸” ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    async def predict(self, market_data: Dict[str, Any], symbol: str) -> EnsemblePrediction:
        """ì•™ìƒë¸” ì˜ˆì¸¡ ìˆ˜í–‰"""
        try:
            # íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
            features = await self.feature_engineer.create_features(market_data, symbol)
            
            if features is None or len(features) == 0:
                raise ValueError("íŠ¹ì„± ìƒì„± ì‹¤íŒ¨")
            
            # ê° ëª¨ë¸ë³„ ì˜ˆì¸¡ ìˆ˜í–‰
            model_predictions = []
            
            for model_name, model in self.models.items():
                try:
                    prediction = await self._predict_single_model(
                        model_name, model, features, symbol
                    )
                    if prediction:
                        model_predictions.append(prediction)
                except Exception as e:
                    logger.warning(f"{model_name} ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            
            if not model_predictions:
                raise ValueError("ëª¨ë“  ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨")
            
            # ì•™ìƒë¸” ê°€ì¤‘ í‰ê·  ê³„ì‚°
            final_prediction = self._combine_predictions(model_predictions, symbol)
            
            return final_prediction
            
        except Exception as e:
            logger.error(f"ì•™ìƒë¸” ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            raise
    
    async def _predict_single_model(
        self, 
        model_name: str, 
        model: Any, 
        features: np.ndarray, 
        symbol: str
    ) -> Optional[ModelPrediction]:
        """ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡"""
        try:
            if model_name in ['lstm', 'transformer']:
                # ë”¥ëŸ¬ë‹ ëª¨ë¸
                direction, confidence, price_change = await model.predict(features)
                features_importance = {}  # ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚° ë³µì¡
            else:
                # ì „í†µì  ML ëª¨ë¸
                if not hasattr(model, 'predict'):
                    # ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
                    return ModelPrediction(
                        model_name=model_name,
                        direction=0.0,
                        confidence=0.1,
                        price_change=0.0,
                        time_horizon=60,
                        features_importance={}
                    )
                
                # 2D íŠ¹ì„±ìœ¼ë¡œ ë³€í™˜ (sklearn ìš”êµ¬ì‚¬í•­)
                if len(features.shape) > 2:
                    features_2d = features.reshape(features.shape[0], -1)
                else:
                    features_2d = features
                
                # ì˜ˆì¸¡ ìˆ˜í–‰
                prediction = model.predict(features_2d[-1:])  # ë§ˆì§€ë§‰ ë°ì´í„°í¬ì¸íŠ¸ ì˜ˆì¸¡
                
                # ê²°ê³¼ í•´ì„
                direction = np.clip(prediction[0], -1.0, 1.0)
                confidence = min(0.8, abs(direction))  # ì „í†µì  ëª¨ë¸ì€ ë³´ìˆ˜ì  ì‹ ë¢°ë„
                price_change = direction * 0.02  # 2% ìµœëŒ€ ë³€ë™ ê°€ì •
                
                # íŠ¹ì„± ì¤‘ìš”ë„ (Random Forestë§Œ ì§€ì›)
                features_importance = {}
                if hasattr(model, 'feature_importances_'):
                    importance = model.feature_importances_
                    feature_names = self.feature_engineer.get_feature_names()
                    features_importance = dict(zip(feature_names[:len(importance)], importance))
            
            return ModelPrediction(
                model_name=model_name,
                direction=direction,
                confidence=confidence,
                price_change=price_change,
                time_horizon=60,  # 1ì‹œê°„ ì˜ˆì¸¡
                features_importance=features_importance
            )
            
        except Exception as e:
            logger.error(f"{model_name} ëª¨ë¸ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return None
    
    def _combine_predictions(
        self, 
        model_predictions: List[ModelPrediction], 
        symbol: str
    ) -> EnsemblePrediction:
        """ì˜ˆì¸¡ ê²°ê³¼ ì•™ìƒë¸” ê²°í•©"""
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        total_weight = 0
        weighted_direction = 0
        weighted_confidence = 0
        weighted_price_change = 0
        
        for pred in model_predictions:
            weight = self.ensemble_weights.get(pred.model_name, 0.25)
            total_weight += weight
            
            weighted_direction += pred.direction * weight
            weighted_confidence += pred.confidence * weight
            weighted_price_change += pred.price_change * weight
        
        if total_weight > 0:
            final_direction = weighted_direction / total_weight
            final_confidence = weighted_confidence / total_weight
            final_price_change = weighted_price_change / total_weight
        else:
            final_direction = 0.0
            final_confidence = 0.1
            final_price_change = 0.0
        
        # ì‹ ë¢°ë„ ì¡°ì • (ëª¨ë¸ ê°„ ì¼ì¹˜ë„ ê³ ë ¤)
        directions = [pred.direction for pred in model_predictions]
        direction_std = np.std(directions) if len(directions) > 1 else 0
        
        # ëª¨ë¸ë“¤ì´ ì¼ì¹˜í• ìˆ˜ë¡ ì‹ ë¢°ë„ ì¦ê°€
        consistency_bonus = max(0, 1.0 - direction_std) * 0.2
        final_confidence = min(1.0, final_confidence + consistency_bonus)
        
        return EnsemblePrediction(
            symbol=symbol,
            final_direction=final_direction,
            final_confidence=final_confidence,
            final_price_change=final_price_change,
            model_predictions=model_predictions,
            ensemble_weights=self.ensemble_weights.copy(),
            prediction_timestamp=datetime.now()
        )
    
    async def update_models(self, feedback_data: Dict[str, Any]):
        """ì„±ê³¼ í”¼ë“œë°±ì„ í†µí•œ ëª¨ë¸ ì—…ë°ì´íŠ¸"""
        try:
            logger.info("ğŸ“ˆ ëª¨ë¸ ì„±ê³¼ í”¼ë“œë°± ì²˜ë¦¬ ì¤‘...")
            
            # ì„±ê³¼ ë°ì´í„° íŒŒì‹±
            predictions_performance = feedback_data.get('predictions', [])
            
            if not predictions_performance:
                logger.warning("ì„±ê³¼ í”¼ë“œë°± ë°ì´í„° ì—†ìŒ")
                return
            
            # ëª¨ë¸ë³„ ì„±ê³¼ ê³„ì‚°
            model_scores = {}
            for perf in predictions_performance:
                model_name = perf.get('model_name')
                actual_outcome = perf.get('actual_outcome', 0)
                predicted_outcome = perf.get('predicted_outcome', 0)
                
                if model_name and model_name in self.models:
                    if model_name not in model_scores:
                        model_scores[model_name] = []
                    
                    # MAE ê³„ì‚°
                    error = abs(actual_outcome - predicted_outcome)
                    model_scores[model_name].append(1.0 / (1.0 + error))  # ì˜¤ì°¨ê°€ ì ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
            
            # ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
            await self._update_ensemble_weights(model_scores)
            
            # ê°œë³„ ëª¨ë¸ ì¬í•™ìŠµ (ë¹„ë™ê¸°)
            asyncio.create_task(self._retrain_models(feedback_data))
            
            logger.info("âœ… ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
    
    async def _update_ensemble_weights(self, model_scores: Dict[str, List[float]]):
        """ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ë™ì  ì¡°ì •"""
        # ê° ëª¨ë¸ì˜ í‰ê·  ì„±ê³¼ ê³„ì‚°
        avg_scores = {}
        for model_name, scores in model_scores.items():
            if scores:
                avg_scores[model_name] = np.mean(scores)
        
        if not avg_scores:
            return
        
        # ì†Œí”„íŠ¸ë§¥ìŠ¤ë¡œ ê°€ì¤‘ì¹˜ ì •ê·œí™”
        total_score = sum(avg_scores.values())
        if total_score > 0:
            for model_name in self.ensemble_weights:
                if model_name in avg_scores:
                    self.ensemble_weights[model_name] = avg_scores[model_name] / total_score
                else:
                    self.ensemble_weights[model_name] *= 0.9  # ì„±ê³¼ ë°ì´í„°ê°€ ì—†ëŠ” ëª¨ë¸ì€ ê°€ì¤‘ì¹˜ ê°ì†Œ
        
        logger.info(f"ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸: {self.ensemble_weights}")
    
    async def _retrain_models(self, feedback_data: Dict[str, Any]):
        """ëª¨ë¸ ì¬í•™ìŠµ (ë°±ê·¸ë¼ìš´ë“œ)"""
        try:
            # ì¬í•™ìŠµ ë°ì´í„° ì¤€ë¹„
            training_data = feedback_data.get('training_data', {})
            
            if not training_data:
                logger.warning("ì¬í•™ìŠµìš© ë°ì´í„° ì—†ìŒ")
                return
            
            # ê° ëª¨ë¸ë³„ ì¬í•™ìŠµ
            for model_name, model in self.models.items():
                if model_name in ['lstm', 'transformer']:
                    # ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¬í•™ìŠµ
                    await model.incremental_train(training_data)
                else:
                    # ì „í†µì  ML ëª¨ë¸ ì¬í•™ìŠµ
                    await self._retrain_ml_model(model_name, model, training_data)
            
            # ëª¨ë¸ ì €ì¥
            await self._save_models()
            
            logger.info("ëª¨ë¸ ì¬í•™ìŠµ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì¬í•™ìŠµ ì˜¤ë¥˜: {e}")
    
    async def _retrain_ml_model(self, model_name: str, model: Any, training_data: Dict[str, Any]):
        """ì „í†µì  ML ëª¨ë¸ ì¬í•™ìŠµ"""
        try:
            # í•™ìŠµ ë°ì´í„° ì¤€ë¹„
            X = np.array(training_data.get('features', []))
            y = np.array(training_data.get('targets', []))
            
            if len(X) < 10:  # ìµœì†Œ ë°ì´í„° ìš”êµ¬ì‚¬í•­
                logger.warning(f"{model_name}: ì¬í•™ìŠµìš© ë°ì´í„° ë¶€ì¡± ({len(X)}ê°œ)")
                return
            
            # 2D íŠ¹ì„±ìœ¼ë¡œ ë³€í™˜
            if len(X.shape) > 2:
                X = X.reshape(X.shape[0], -1)
            
            # ì ì§„ì  í•™ìŠµ ë˜ëŠ” ì „ì²´ ì¬í•™ìŠµ
            if hasattr(model, 'partial_fit'):
                model.partial_fit(X, y)
            else:
                model.fit(X, y)
            
            logger.info(f"{model_name} ì¬í•™ìŠµ ì™„ë£Œ ({len(X)}ê°œ ìƒ˜í”Œ)")
            
        except Exception as e:
            logger.error(f"{model_name} ì¬í•™ìŠµ ì˜¤ë¥˜: {e}")
    
    async def calculate_accuracy(self) -> float:
        """ì „ì²´ ëª¨ë¸ ì •í™•ë„ ê³„ì‚°"""
        try:
            # ìµœê·¼ ì„±ê³¼ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•ë„ ê³„ì‚°
            if not self.performance_history:
                return 0.5  # ê¸°ë³¸ê°’
            
            recent_performances = []
            cutoff_time = datetime.now() - timedelta(days=7)  # ìµœê·¼ 7ì¼
            
            for timestamp, performance in self.performance_history.items():
                if timestamp > cutoff_time:
                    recent_performances.append(performance)
            
            if not recent_performances:
                return 0.5
            
            # í‰ê·  ì •í™•ë„ ê³„ì‚°
            avg_accuracy = np.mean([p.get('accuracy', 0.5) for p in recent_performances])
            return min(1.0, max(0.0, avg_accuracy))
            
        except Exception as e:
            logger.error(f"ì •í™•ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.5
    
    async def _load_existing_models(self):
        """ê¸°ì¡´ ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ"""
        try:
            model_dir = self.config.get('model_save_dir', 'saved_models')
            
            # Random Forest ë¡œë“œ
            try:
                rf_path = f"{model_dir}/random_forest.joblib"
                self.models['random_forest'] = joblib.load(rf_path)
                logger.info("Random Forest ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            except:
                logger.info("Random Forest ëª¨ë¸ ì—†ìŒ, ìƒˆë¡œ ìƒì„±")
            
            # XGBoost ë¡œë“œ
            try:
                xgb_path = f"{model_dir}/xgboost.json"
                self.models['xgboost'].load_model(xgb_path)
                logger.info("XGBoost ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            except:
                logger.info("XGBoost ëª¨ë¸ ì—†ìŒ, ìƒˆë¡œ ìƒì„±")
            
        except Exception as e:
            logger.warning(f"ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    async def _save_models(self):
        """ëª¨ë¸ ì €ì¥"""
        try:
            model_dir = self.config.get('model_save_dir', 'saved_models')
            import os
            os.makedirs(model_dir, exist_ok=True)
            
            # Random Forest ì €ì¥
            if hasattr(self.models['random_forest'], 'predict'):
                rf_path = f"{model_dir}/random_forest.joblib"
                joblib.dump(self.models['random_forest'], rf_path)
            
            # XGBoost ì €ì¥
            if hasattr(self.models['xgboost'], 'save_model'):
                xgb_path = f"{model_dir}/xgboost.json"
                self.models['xgboost'].save_model(xgb_path)
            
            # ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì €ì¥
            weights_path = f"{model_dir}/ensemble_weights.json"
            import json
            with open(weights_path, 'w') as f:
                json.dump(self.ensemble_weights, f)
            
            logger.info("ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì €ì¥ ì˜¤ë¥˜: {e}")

    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            "ensemble_weights": self.ensemble_weights,
            "available_models": list(self.models.keys()),
            "model_configs": self.model_configs,
            "performance_history_count": len(self.performance_history)
        }